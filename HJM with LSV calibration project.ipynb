{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3429977-2f65-4ba3-a721-df22019ffe9b",
   "metadata": {},
   "source": [
    "# HJM model with stochastic volatility (CIR)\n",
    "\n",
    "This notebook implements a single-factor HJM forward-rate model with CEV scaling and a single mean-reverting stochastic volatility factor, calibrated to caplet and swaption markets.  \n",
    "\n",
    "\n",
    "\n",
    "### Model\n",
    "\n",
    "**Forward-rate SDE (risk-neutral measure $(\\mathbb{Q})$):**\n",
    "$$\n",
    "{\\;df(t,T) \\;=\\; \\mu(t,T)\\,dt \\;+\\; \\sigma(t,T)\\,dW_t\\;}\n",
    "$$\n",
    "\n",
    "**_where:_**\n",
    "\n",
    "Instantaneous forward volatility (CEV × amplitude):\n",
    "$$\n",
    "{\\sigma(t,T) = v_t\\,\\phi(t,T)\\,\\bigl[f(t,T)+\\delta\\bigr]^{\\beta}}\n",
    "$$\n",
    "where: \n",
    "- $f(t,T)$ = instantaneous forward rate maturing at $T$ observed at time $t$.  \n",
    "- $v_t$ = scalar stochastic volatility (amplitude).  \n",
    "- $\\phi(t,T)$ = deterministic shape (term-structure), e.g. $\\phi(t,T) = a^{-b(T-t)}$.  \n",
    "- $\\beta$ = CEV exponent.  \n",
    "- $\\delta \\geq 0$ = small shift (default $1\\times 10^{-4}$) to handle near-zero/negative rates.  \n",
    "\n",
    "where:\n",
    "\n",
    "**Stochastic volatility SDE (CIR / Heston-like):**\n",
    "$$\n",
    "{\\;dv_t \\;=\\; \\kappa(\\theta - v_t)\\,dt \\;+\\; \\xi\\sqrt{v_t}\\,dZ_t\\;}\n",
    "$$\n",
    "where:\n",
    "- $\\kappa$ = speed of mean reversion, $\\theta$ = long-run level, $\\xi$ = vol-of-vol.  \n",
    "- Use Andersen QE exact/approx scheme where possible; fallback to full-truncation Euler for robustness.\n",
    "\n",
    "**Correlation between the driving noises:**\n",
    "The two Brownian motions $W_t$ (for forwards) and $Z_t$ (for volatility) satisfy\n",
    "$$\n",
    "{\\;d\\langle W,Z\\rangle_t \\;=\\; \\rho\\,dt\\;}\n",
    "$$\n",
    "with $\\rho \\in [-1,1]$ (typical bounds used in calibration code: $[-0.99,0.99]$).\n",
    "\n",
    "**HJM no-arbitrage drift:**\n",
    "$$\n",
    "{\\;\\mu(t,T) \\;=\\; \\sigma(t,T)\\,\\int_{t}^{T}\\sigma(t,s)\\,ds\\;.}\n",
    "$$\n",
    "- In practice the integral $\\int_t^T \\sigma(t,s)\\,ds$ is approximated numerically on the model $T$-grid (trapezoid / Simpson).\n",
    "\n",
    "\n",
    "\n",
    "Deterministic shape (example parameterisation):\n",
    "A simple, calibratable choice used in the code:\n",
    "$$\n",
    "\\phi(t,T) = a \\, e^{-b (T - t)} \n",
    "$$\n",
    "with $a > 0$, $b \\ge 0$ exposed as calibration parameters.\n",
    "\n",
    "\n",
    "\n",
    "### Process\n",
    "\n",
    "**1. Configuration & environment**  \n",
    "   - CONFIG dictionary: random number generator (RNG) seed, MC path counts, grid resolution, weights for swaption vs caplet, file paths.\n",
    "\n",
    "**2. Synthetic market data generation** (`/data/*.csv`)  \n",
    "   - Create deterministic OIS/RFR curve CSV (`curve.csv`) with times, zero rates and discount factors.  \n",
    "   - Create synthetic caplet vol matrix (`caplet_quotes.csv`) and synthetic swaption surface (`swaption_quotes.csv`).  \n",
    "   - Files are deterministic (seeded) so runs are reproducible.\n",
    "\n",
    "**3. Bootstrapping / interpolation**  \n",
    "   - Read `curve.csv`, build interpolant \\(P(0,t)\\) (log-linear interpolation of discount factors).  \n",
    "   - Compute initial instantaneous forward curve $f(0,T) = -\\partial_T \\ln P(0,T)$ on a fixed $T$-grid.\n",
    "\n",
    "**4. Model initialisation**  \n",
    "   - Instantiate `HJMModel` with: T-grid, initial forwards $f(0,T)$, parameter struct ($a, b, \\beta, \\delta, \\kappa, \\theta, \\xi, \\rho, v_0$)\n",
    ", and $\\phi(t,T)$ function.\n",
    "\n",
    "**5. Monte-Carlo simulation engine**  \n",
    "   - Simulate forward-curve paths and the volatility factor $(v_t)$ using correlated normals (common random numbers, optional antithetic variates).  \n",
    "   - Use full-truncation Euler for $v_t$.  \n",
    "   - Compute HJM drift $\\mu(t,T)$ via numerical quadrature on the $T$-grid at each step.  \n",
    "\n",
    "**6. Instrument pricers (MC-based)**  \n",
    "   - **Caplet pricer:** uses simulated $f(\\text{expiry}, \\text{expiry}+\\tau)$ to compute payoff $\\mathrm{DF}\\,\\tau\\,\\max(F-K,0)$.\n",
    "   - **Swaption pricer:** approximate via forward swap rate and annuity (MC used to evolve state to expiry where needed).  \n",
    "   - Provide Black implied-vol inversion utilities to compare model prices to quoted vols.\n",
    "\n",
    "**7. Calibration — two stages**  \n",
    "   - **Stage A (ATM term structure):** calibrate $(a,b,\\beta)$ to match ATM caplet & ATM swaption term structures (fast MC or approximations).  \n",
    "  Swaption vs caplet weights are configurable; default places higher weight on swaption surface for mid/long tenors.  \n",
    "\n",
    "   - **Stage B (smiles):** fix Stage A parameters and calibrate $(\\kappa,\\theta,\\xi,\\rho,v_0)$ to capture smile/skew across strikes/deltas using Monte Carlo pricing.  \n",
    "  Use global $\\rightarrow$ local optimisation strategy in practice (the notebook uses local methods for speed).  \n",
    "\n",
    "\n",
    "**8. Diagnostics & outputs**  \n",
    "   - Save: `outputs/calibration_results.json`, `outputs/calibrated_parameters.json`, `outputs/model_vs_market_caplets.csv`, `outputs/model_vs_market_swaptions.csv`.  \n",
    "   - Plots: ATM caplet fit, ATM swaption surface fit, selected smile comparisons (PNG files under `outputs/plots/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a193f4-9dee-431d-ae4a-0b08bcf6cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Dependencies & CONFIG\n",
    "# ----------------------------\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import shutil\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate, optimize, stats\n",
    "from scipy.optimize import brentq\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "CONFIG = {\n",
    "    \"currency\": \"USD\",                # SOFR -> USD. Use \"GBP\"->SONIA, \"EUR\"->ESTR\n",
    "    \"seed\": 42,\n",
    "    \"n_paths_stageA\": 2,              # demo; 2 instead of 2000 for speed/illustration on personal laptop\n",
    "    \"n_paths_stageB\": 3,              # increase for more accurate Stage B; 3 instead of 12000 number for speed/illustration on personal laptop\n",
    "    \"n_steps_per_year\": 4,            # 4 instead of 12; unrealistically low to save processing speed on personal laptop\n",
    "    \"swaption_weight\": 0.7,\n",
    "    \"cap_weight\": 0.3,\n",
    "    \"fast_mode\": True,\n",
    "    \"phi_init\": {\"a\": 0.02, \"b\": 0.5},\n",
    "    \"beta_init\": 0.0,\n",
    "    \"vol_shift\": 1e-4,\n",
    "    \"qe_scheme\": False,               # not used; full-truncation Euler used\n",
    "    \"output_dir\": \"outputs\",\n",
    "    \"data_dir\": \"data\",\n",
    "}\n",
    "np.random.seed(CONFIG[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "302eb236-7b86-4835-b5cf-c8ffcb084d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Utilities & IO Setup\n",
    "# --------------------\n",
    "def ensure_dirs():\n",
    "    for d in [CONFIG[\"data_dir\"], CONFIG[\"output_dir\"], os.path.join(CONFIG[\"output_dir\"], \"plots\")]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "ensure_dirs()\n",
    "\n",
    "def tenor_to_years(tenor: str) -> float:\n",
    "    \"\"\"Convert tenor like '1D','1W','1M','3M','6M','1Y','5Y' to years (approx).\"\"\"\n",
    "    tenor = tenor.strip().upper()\n",
    "    if tenor.endswith('D'):\n",
    "        return int(tenor[:-1]) / 365.0\n",
    "    if tenor.endswith('W'):\n",
    "        return int(tenor[:-1]) * 7 / 365.0\n",
    "    if tenor.endswith('M'):\n",
    "        return int(tenor[:-1]) / 12.0\n",
    "    if tenor.endswith('Y'):\n",
    "        return int(tenor[:-1])\n",
    "    raise ValueError(\"Unknown tenor format: \" + tenor)\n",
    "\n",
    "def save_csv(df: pd.DataFrame, path: str):\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Saved: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f636cace-c4e6-40d1-acbc-9d00d3bc41ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\curve.csv\n",
      "Saved: data\\caplet_quotes.csv\n",
      "Saved: data\\swaption_quotes.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Dummy market data files\n",
    "# -----------------------\n",
    "def generate_dummy_curve(path: str, currency: str = \"USD\", base_rate: float = 0.02):\n",
    "    \"\"\"Generate a deterministic OIS/RFR-like curve and save to CSV.\"\"\"\n",
    "    tenors = [\"1M\",\"3M\",\"6M\",\"1Y\",\"2Y\",\"3Y\",\"5Y\",\"7Y\",\"10Y\",\"15Y\",\"20Y\",\"30Y\"]\n",
    "    times = np.array([tenor_to_years(t) for t in tenors])\n",
    "    zero_rates = base_rate + 0.002 * np.log1p(times * 10)\n",
    "    discount_factors = np.exp(-zero_rates * times)\n",
    "    df = pd.DataFrame({\n",
    "        \"tenor\": tenors,\n",
    "        \"time\": times,\n",
    "        \"zero_rate\": zero_rates,\n",
    "        \"discount_factor\": discount_factors,\n",
    "        \"currency\": currency,\n",
    "        \"date\": pd.Timestamp.today().strftime(\"%Y-%m-%d\"),\n",
    "        \"rate_type\": \"continuous\"\n",
    "    })\n",
    "    save_csv(df, path)\n",
    "    return df\n",
    "\n",
    "def generate_dummy_caplet_vols(path: str, currency: str = \"USD\"):\n",
    "    \"\"\"Generate synthetic caplet vol quotes: expiries x strikes.\"\"\"\n",
    "    expiries = [\"6M\",\"1Y\",\"2Y\",\"3Y\",\"5Y\",\"7Y\"]\n",
    "    strikes = [-0.005, 0.0, 0.01, 0.02, 0.03]\n",
    "    rows = []\n",
    "    atm_base = {\"6M\":0.008, \"1Y\":0.01, \"2Y\":0.015, \"3Y\":0.017, \"5Y\":0.02, \"7Y\":0.023}\n",
    "    for e in expiries:\n",
    "        for k in strikes:\n",
    "            atm = atm_base[e]\n",
    "            vol = atm * (1.0 + 0.5 * (0.02 - k)) + 0.001 * abs(k)\n",
    "            rows.append({\"expiry\": e, \"strike\": round(k,4), \"vol\": max(vol, 0.0005), \"vol_type\": \"normal\", \"currency\": currency})\n",
    "    df = pd.DataFrame(rows)\n",
    "    save_csv(df, path)\n",
    "    return df\n",
    "\n",
    "def generate_dummy_swaption_vols(path: str, currency: str = \"USD\"):\n",
    "    \"\"\"Generate synthetic swaption vol surface: expiry x tenor x moneyness\"\"\"\n",
    "    expiries = [\"6M\",\"1Y\",\"2Y\",\"3Y\",\"5Y\",\"10Y\"]\n",
    "    tenors = [\"1Y\",\"2Y\",\"5Y\",\"10Y\"]\n",
    "    moneyness = [\"-25D\",\"ATM\",\"25D\"]\n",
    "    rows = []\n",
    "    atm_table = {\n",
    "        (\"6M\",\"1Y\"):0.007, (\"6M\",\"2Y\"):0.008, (\"6M\",\"5Y\"):0.01, (\"6M\",\"10Y\"):0.012,\n",
    "        (\"1Y\",\"1Y\"):0.009, (\"1Y\",\"2Y\"):0.011, (\"1Y\",\"5Y\"):0.013, (\"1Y\",\"10Y\"):0.015,\n",
    "        (\"2Y\",\"1Y\"):0.011, (\"2Y\",\"2Y\"):0.013, (\"2Y\",\"5Y\"):0.015, (\"2Y\",\"10Y\"):0.017,\n",
    "        (\"3Y\",\"1Y\"):0.012, (\"3Y\",\"2Y\"):0.014, (\"3Y\",\"5Y\"):0.016, (\"3Y\",\"10Y\"):0.018,\n",
    "        (\"5Y\",\"1Y\"):0.013, (\"5Y\",\"2Y\"):0.015, (\"5Y\",\"5Y\"):0.018, (\"5Y\",\"10Y\"):0.02,\n",
    "        (\"10Y\",\"1Y\"):0.016, (\"10Y\",\"2Y\"):0.018, (\"10Y\",\"5Y\"):0.02, (\"10Y\",\"10Y\"):0.022\n",
    "    }\n",
    "    for e in expiries:\n",
    "        for t in tenors:\n",
    "            atm = atm_table.get((e,t), 0.014)\n",
    "            for m in moneyness:\n",
    "                if m == \"ATM\":\n",
    "                    vol = atm\n",
    "                elif m == \"-25D\":\n",
    "                    vol = atm * 1.12\n",
    "                else:\n",
    "                    vol = atm * 0.92\n",
    "                rows.append({\"expiry\": e, \"tenor\": t, \"moneyness\": m, \"vol\": max(vol, 1e-4), \"vol_type\": \"black\", \"currency\": currency})\n",
    "    df = pd.DataFrame(rows)\n",
    "    save_csv(df, path)\n",
    "    return df\n",
    "\n",
    "# create files (if absent)\n",
    "curve_csv = os.path.join(CONFIG[\"data_dir\"], \"curve.csv\")\n",
    "caplet_csv = os.path.join(CONFIG[\"data_dir\"], \"caplet_quotes.csv\")\n",
    "swaption_csv = os.path.join(CONFIG[\"data_dir\"], \"swaption_quotes.csv\")\n",
    "\n",
    "if not os.path.exists(curve_csv):\n",
    "    generate_dummy_curve(curve_csv, currency=CONFIG[\"currency\"])\n",
    "if not os.path.exists(caplet_csv):\n",
    "    generate_dummy_caplet_vols(caplet_csv, currency=CONFIG[\"currency\"])\n",
    "if not os.path.exists(swaption_csv):\n",
    "    generate_dummy_swaption_vols(swaption_csv, currency=CONFIG[\"currency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d21b19d-d81b-425a-8380-70f39f9cd767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Bootstrapping helpers (simple)\n",
    "# -------------------------------\n",
    "def read_curve(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.sort_values(\"time\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def interp_discount(df_curve: pd.DataFrame) -> Callable[[float], float]:\n",
    "    \"\"\"Return a function P(0,t) by linear interpolation in log DF space.\"\"\"\n",
    "    times = df_curve[\"time\"].values\n",
    "    dfs = df_curve[\"discount_factor\"].values\n",
    "    ln_dfs = np.log(np.maximum(dfs, 1e-16))\n",
    "    interp_fn = interpolate.interp1d(times, ln_dfs, kind=\"linear\", fill_value=\"extrapolate\")\n",
    "    return lambda t: float(np.exp(interp_fn(t)))\n",
    "\n",
    "def forward_from_discount(P: Callable[[float], float], times: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Finite difference estimate of instantaneous forward rates at supplied times.\"\"\"\n",
    "    f = []\n",
    "    for t in times:\n",
    "        h = max(1e-5, min(0.01, t*1e-2))\n",
    "        if t - h < 0:\n",
    "            val = -(math.log(P(t+h)) - math.log(P(t))) / h\n",
    "        else:\n",
    "            val = -(math.log(P(t+h)) - math.log(P(t-h))) / (2*h)\n",
    "        f.append(float(val))\n",
    "    return np.array(f)\n",
    "\n",
    "curve_df = read_curve(curve_csv)\n",
    "P0 = interp_discount(curve_df)\n",
    "curve_times = curve_df[\"time\"].values\n",
    "f0_times = np.linspace(0.01, max(curve_times)*1.0, num=60)   # model T-grid\n",
    "f0_vals = forward_from_discount(P0, f0_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcdf9635-43aa-4d3a-b079-b1816c0561d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# HJM Model: discretised forward-curve MC\n",
    "# ----------------------------------------\n",
    "@dataclass\n",
    "class HJMParams:\n",
    "    a: float\n",
    "    b: float\n",
    "    beta: float\n",
    "    delta: float\n",
    "    kappa: float\n",
    "    theta: float\n",
    "    xi: float\n",
    "    rho: float\n",
    "    v0: float\n",
    "\n",
    "class HJMModel:\n",
    "    \"\"\"Single-factor HJM with CEV scaling and one stochastic volatility factor v_t.\"\"\"\n",
    "    def __init__(self, times: np.ndarray, f0: np.ndarray, params: HJMParams,\n",
    "                 phi_fn: Optional[Callable[[float, float], float]] = None,\n",
    "                 n_steps_per_year: int = 4, seed: int = 42):    # 4 instead of 12 n_steps_per_year to save processor speed on personal laptop\n",
    "        self.times = np.array(times)\n",
    "        self.f0 = np.array(f0)\n",
    "        self.params = params\n",
    "        self.n_steps_per_year = n_steps_per_year\n",
    "        self.dt = 1.0 / n_steps_per_year\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed)\n",
    "        self.Tgrid = self.times.copy()\n",
    "        if phi_fn is None:\n",
    "            self.phi_fn = lambda t, T: params.a * np.exp(-params.b * (T - t)) if T >= t else 0.0\n",
    "        else:\n",
    "            self.phi_fn = phi_fn\n",
    "\n",
    "    def sigma(self, t_idx: Optional[int], t: float, f_vec: np.ndarray, v_t: float) -> np.ndarray:\n",
    "        sig = np.zeros_like(f_vec, dtype=float)\n",
    "        for i, T in enumerate(self.Tgrid):\n",
    "            if T >= t:\n",
    "                phi = self.phi_fn(t, T)\n",
    "                base = max(f_vec[i] + self.params.delta, 0.0)\n",
    "                sig[i] = v_t * phi * (base ** self.params.beta)\n",
    "            else:\n",
    "                sig[i] = 0.0\n",
    "        return sig\n",
    "\n",
    "    def hjm_drift(self, t: float, f_vec: np.ndarray, v_t: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute μ(t,T) = σ(t,T) * ∫_t^T σ(t,s) ds using cumulative trapezoid on the model T-grid.\n",
    "        Uses scipy.integrate.cumulative_trapezoid (fast, O(n)).\n",
    "        \"\"\"\n",
    "        sig = self.sigma(None, t, f_vec, v_t)\n",
    "        mu = np.zeros_like(sig)\n",
    "        mask = self.Tgrid >= t\n",
    "        if not np.any(mask):\n",
    "            return mu\n",
    "    \n",
    "        Tsub = self.Tgrid[mask].copy()\n",
    "        sig_sub = sig[mask].copy()\n",
    "    \n",
    "        # If earliest Tsub > t, estimate sigma(t,t) and prepend so integral starts at t\n",
    "        prepended = False\n",
    "        if Tsub[0] > t:\n",
    "            interp_f = interpolate.interp1d(self.Tgrid, f_vec, kind=\"linear\", fill_value=\"extrapolate\")\n",
    "            f_at_t = float(interp_f(t))\n",
    "            base = max(f_at_t + self.params.delta, 0.0)\n",
    "            sigma_at_t = v_t * self.phi_fn(t, t) * (base ** self.params.beta)\n",
    "            Tsub = np.concatenate(([t], Tsub))\n",
    "            sig_sub = np.concatenate(([sigma_at_t], sig_sub))\n",
    "            prepended = True\n",
    "    \n",
    "        # cumulative_trapezoid from scipy.integrate returns integral[j] = ∫_{Tsub[0]}^{Tsub[j]} sig_sub(s) ds\n",
    "        # import cumulative_trapezoid at the top: from scipy.integrate import cumulative_trapezoid\n",
    "        integral = cumulative_trapezoid(sig_sub, Tsub, initial=0.0)\n",
    "    \n",
    "        # mu(t,T_j) = sigma(t,T_j) * integral_j\n",
    "        mu_masked = sig_sub * integral\n",
    "    \n",
    "        # if we prepended a t point, the first element corresponds to T==t and integral==0, so drop it\n",
    "        mu_vals = mu_masked[1:] if prepended else mu_masked\n",
    "    \n",
    "        mu[mask] = mu_vals\n",
    "        return mu\n",
    "\n",
    "    def simulate_paths(self, n_paths: int, Tsim: float, n_steps: Optional[int] = None, antithetic: bool = True):\n",
    "        if n_steps is None:\n",
    "            n_steps = max(1, int(np.ceil(Tsim * self.n_steps_per_year)))\n",
    "        dt = Tsim / n_steps\n",
    "        times = np.linspace(0.0, Tsim, n_steps+1)\n",
    "        n_T = len(self.Tgrid)\n",
    "        f_paths = np.zeros((n_paths, n_steps+1, n_T), dtype=float)\n",
    "        v_paths = np.zeros((n_paths, n_steps+1), dtype=float)\n",
    "        f_paths[:, 0, :] = np.tile(self.f0, (n_paths, 1))\n",
    "        v_paths[:, 0] = self.params.v0\n",
    "\n",
    "        rng = np.random.RandomState(self.seed)\n",
    "        if antithetic:\n",
    "            half = int(np.ceil(n_paths/2))\n",
    "            Z1 = rng.normal(size=(half, n_steps))\n",
    "            Z2 = rng.normal(size=(half, n_steps))\n",
    "            Z1 = np.vstack([Z1, -Z1])[:n_paths, :]\n",
    "            Z2 = np.vstack([Z2, -Z2])[:n_paths, :]\n",
    "            eps_W = Z1\n",
    "            eps_Z = Z2\n",
    "        else:\n",
    "            eps_W = rng.normal(size=(n_paths, n_steps))\n",
    "            eps_Z = rng.normal(size=(n_paths, n_steps))\n",
    "\n",
    "        rho = self.params.rho\n",
    "        eps_Z = rho * eps_W + math.sqrt(max(0.0, 1.0 - rho**2)) * eps_Z\n",
    "\n",
    "        for step in range(n_steps):\n",
    "            t = times[step]\n",
    "            sqrt_dt = math.sqrt(dt)\n",
    "            for p in range(n_paths):\n",
    "                f_cur = f_paths[p, step, :].copy()\n",
    "                v_cur = max(v_paths[p, step], 0.0)\n",
    "                sig_vec = self.sigma(step, t, f_cur, v_cur)\n",
    "                mu_vec = self.hjm_drift(t, f_cur, v_cur)\n",
    "                dW = sqrt_dt * eps_W[p, step]\n",
    "                dZ = sqrt_dt * eps_Z[p, step]\n",
    "                f_next = f_cur + mu_vec * dt + sig_vec * dW\n",
    "                f_next = np.maximum(f_next, -0.99)\n",
    "                kappa, theta, xi = self.params.kappa, self.params.theta, self.params.xi\n",
    "                v_next = v_cur + kappa * (theta - v_cur) * dt + xi * math.sqrt(max(v_cur, 0.0)) * dZ\n",
    "                v_next = max(v_next, 1e-12)\n",
    "                f_paths[p, step+1, :] = f_next\n",
    "                v_paths[p, step+1] = v_next\n",
    "        return f_paths, v_paths, times\n",
    "\n",
    "    # Pricing wrappers (bound to class)\n",
    "    def price_caplet_mc(self, strike: float, expiry: float, accrual: float, payoff_df_fn: Callable[[float], float],\n",
    "                        n_paths: int = 20, n_steps: Optional[int] = None) -> float:\n",
    "        f_paths, v_paths, times = self.simulate_paths(n_paths=n_paths, Tsim=expiry, n_steps=n_steps, antithetic=True)\n",
    "        target_T = expiry + accrual\n",
    "        idx = np.argmin(np.abs(self.Tgrid - target_T))\n",
    "        F_at_expiry = f_paths[:, -1, idx]\n",
    "        DF_pay = payoff_df_fn(target_T)\n",
    "        payoffs = np.maximum(F_at_expiry - strike, 0.0) * accrual * DF_pay\n",
    "        price = np.mean(payoffs)\n",
    "        return float(price)\n",
    "\n",
    "    def price_swaption_mc(self, expiry: float, swap_tenor: float, fixed_rate: float, payment_freq: float,\n",
    "                          payoff_df_fn: Callable[[float], float], n_paths: int = 20, n_steps: Optional[int] = None) -> float:\n",
    "        f_paths, v_paths, times = self.simulate_paths(n_paths=n_paths, Tsim=expiry, n_steps=n_steps, antithetic=True)\n",
    "        num_payments = int(round(swap_tenor * payment_freq))\n",
    "        pay_times = np.array([expiry + (k+1)/payment_freq for k in range(num_payments)])\n",
    "        df_payments = np.array([payoff_df_fn(pt) for pt in pay_times])\n",
    "        accrual = 1.0 / payment_freq\n",
    "        annuity = np.sum(df_payments) * accrual\n",
    "        P_start = payoff_df_fn(expiry)\n",
    "        P_end = payoff_df_fn(expiry + swap_tenor)\n",
    "        S = (P_start - P_end) / annuity if annuity > 0 else 0.0\n",
    "        price = P_start * max(S - fixed_rate, 0.0) * annuity\n",
    "        return float(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1f5c100-902b-48bc-84a0-d12034b6a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Black & Bachelier helpers\n",
    "# (Robust implied vol inversion)\n",
    "# ------------------------\n",
    "def black_caplet_price(F: float, K: float, sigma: float, tau: float, DF: float) -> float:\n",
    "    if sigma <= 0 or tau <= 0:\n",
    "        return DF * tau * max(F - K, 0.0)\n",
    "    std = sigma * math.sqrt(tau)\n",
    "    if std <= 0:\n",
    "        return DF * tau * max(F - K, 0.0)\n",
    "    if K <= 0 or F <= 0:\n",
    "        return DF * tau * max(F - K, 0.0)\n",
    "    d1 = (math.log(F / K) + 0.5 * std ** 2) / std\n",
    "    d2 = d1 - std\n",
    "    price = DF * tau * (F * stats.norm.cdf(d1) - K * stats.norm.cdf(d2))\n",
    "    return float(price)\n",
    "\n",
    "def bachelier_caplet_price(F: float, K: float, sigmaN: float, tau: float, DF: float) -> float:\n",
    "    sigmaN_sqrt = sigmaN * math.sqrt(tau)\n",
    "    if sigmaN_sqrt <= 0:\n",
    "        return DF * tau * max(F - K, 0.0)\n",
    "    x = (F - K) / sigmaN_sqrt\n",
    "    price = DF * tau * ((F - K) * stats.norm.cdf(x) + sigmaN_sqrt * stats.norm.pdf(x))\n",
    "    return float(price)\n",
    "\n",
    "def implied_bachelier_vol_from_price_caplet(target_price, F, K, tau, DF, vol_min=1e-8, vol_max=5.0):\n",
    "    price_at_0 = DF * tau * max(F - K, 0.0)\n",
    "    price_at_inf = DF * tau * F\n",
    "    if target_price <= price_at_0 + 1e-14:\n",
    "        return 0.0\n",
    "    if target_price >= price_at_inf - 1e-14:\n",
    "        return vol_max\n",
    "    def f(volN):\n",
    "        return bachelier_caplet_price(F, K, volN, tau, DF) - target_price\n",
    "    try:\n",
    "        volN = brentq(f, vol_min, vol_max, maxiter=60, xtol=1e-12)\n",
    "        return float(volN)\n",
    "    except Exception:\n",
    "        return float(np.nan)\n",
    "\n",
    "def implied_black_vol_from_price_caplet(target_price, F, K, tau, DF, vol_min=1e-8, vol_max=5.0, tol=1e-12):\n",
    "    price_at_0 = DF * tau * max(F - K, 0.0)\n",
    "    price_at_inf = DF * tau * F\n",
    "    if target_price <= price_at_0 + 1e-14:\n",
    "        return 0.0\n",
    "    if target_price >= price_at_inf - 1e-14:\n",
    "        return vol_max\n",
    "    if K <= 0.0 or F <= 0.0:\n",
    "        return implied_bachelier_vol_from_price_caplet(target_price, F, K, tau, DF, vol_min, vol_max)\n",
    "    def price_minus_target(sigma):\n",
    "        return black_caplet_price(F, K, sigma, tau, DF) - target_price\n",
    "    try:\n",
    "        f_low = price_minus_target(vol_min)\n",
    "        f_high = price_minus_target(vol_max)\n",
    "        if f_low * f_high > 0:\n",
    "            vol_max2 = 50.0\n",
    "            f_high2 = price_minus_target(vol_max2)\n",
    "            if f_low * f_high2 > 0:\n",
    "                return implied_bachelier_vol_from_price_caplet(target_price, F, K, tau, DF, vol_min, vol_max)\n",
    "            vol_upper = vol_max2\n",
    "        else:\n",
    "            vol_upper = vol_max\n",
    "        vol_root = brentq(price_minus_target, vol_min, vol_upper, xtol=tol, maxiter=100)\n",
    "        return float(vol_root)\n",
    "    except Exception:\n",
    "        return implied_bachelier_vol_from_price_caplet(target_price, F, K, tau, DF, vol_min, vol_max)\n",
    "\n",
    "def black_swaption_price(S0: float, K: float, sigma: float, T: float, annuity: float) -> float:\n",
    "    if sigma <= 0 or T <= 0:\n",
    "        return annuity * max(S0 - K, 0.0)\n",
    "    std = sigma * math.sqrt(T)\n",
    "    if std <= 0:\n",
    "        return annuity * max(S0 - K, 0.0)\n",
    "    d1 = (math.log(S0 / K) + 0.5 * std ** 2) / std\n",
    "    d2 = d1 - std\n",
    "    price = annuity * (S0 * stats.norm.cdf(d1) - K * stats.norm.cdf(d2))\n",
    "    return price\n",
    "\n",
    "def implied_black_vol_from_price_swaption(S0: float, K: float, T: float, annuity: float, market_price: float):\n",
    "    price_at_0 = annuity * max(S0 - K, 0.0)\n",
    "    price_at_inf = annuity * S0\n",
    "    if market_price <= price_at_0 + 1e-14:\n",
    "        return 0.0\n",
    "    if market_price >= price_at_inf - 1e-14:\n",
    "        return 5.0\n",
    "    def obj(sigma):\n",
    "        return black_swaption_price(S0, K, sigma, T, annuity) - market_price\n",
    "    try:\n",
    "        vol = brentq(obj, 1e-8, 5.0)\n",
    "        return float(vol)\n",
    "    except Exception:\n",
    "        return float(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4cfb790-48c2-462a-b705-1da65a084eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Market <-> model mapping helpers\n",
    "# -------------------------------\n",
    "curve_df = read_curve(curve_csv)\n",
    "P0 = interp_discount(curve_df)\n",
    "def payoff_df_fn(t: float) -> float:\n",
    "    return float(P0(max(1e-8, t)))\n",
    "\n",
    "caplet_df = pd.read_csv(caplet_csv)\n",
    "swaption_df = pd.read_csv(swaption_csv)\n",
    "\n",
    "def extract_atm_caplet_vols(caplet_df: pd.DataFrame) -> Dict[float, float]:\n",
    "    atm = {}\n",
    "    for expiry_str, group in caplet_df.groupby(\"expiry\"):\n",
    "        T = tenor_to_years(expiry_str)\n",
    "        group = group.copy()\n",
    "        group[\"strike_abs\"] = np.abs(group[\"strike\"])\n",
    "        row = group.loc[group[\"strike_abs\"].idxmin()]\n",
    "        atm[T] = float(row[\"vol\"])\n",
    "    return atm\n",
    "\n",
    "def extract_atm_swaption_vols(swap_df: pd.DataFrame) -> Dict[Tuple[float,float], float]:\n",
    "    atm = {}\n",
    "    for (expiry_str, tenor_str), group in swap_df.groupby([\"expiry\", \"tenor\"]):\n",
    "        Texp = tenor_to_years(expiry_str)\n",
    "        Tten = tenor_to_years(tenor_str)\n",
    "        row = group[group[\"moneyness\"] == \"ATM\"].iloc[0]\n",
    "        atm[(Texp, Tten)] = float(row[\"vol\"])\n",
    "    return atm\n",
    "\n",
    "atm_caplet = extract_atm_caplet_vols(caplet_df)\n",
    "atm_swaption = extract_atm_swaption_vols(swaption_df)\n",
    "\n",
    "def model_caplet_implied_vol(hjm: HJMModel, expiry: float, accrual: float, strike: float, n_paths: int) -> float:\n",
    "    price = hjm.price_caplet_mc(strike=strike, expiry=expiry, accrual=accrual, payoff_df_fn=payoff_df_fn, n_paths=n_paths)\n",
    "    target_T = expiry + accrual\n",
    "    idx = np.argmin(np.abs(hjm.Tgrid - target_T))\n",
    "    F0 = hjm.f0[idx]\n",
    "    DF = payoff_df_fn(target_T)\n",
    "    vol = implied_black_vol_from_price_caplet(price, F0, strike, accrual, DF)\n",
    "    return vol\n",
    "\n",
    "def model_swaption_implied_vol(hjm: HJMModel, expiry: float, tenor: float, n_paths: int, payment_freq: float = 1.0) -> float:\n",
    "    num_payments = int(round(tenor * payment_freq))\n",
    "    pay_times = np.array([expiry + (k+1)/payment_freq for k in range(num_payments)])\n",
    "    df_payments = np.array([payoff_df_fn(pt) for pt in pay_times])\n",
    "    accrual = 1.0 / payment_freq\n",
    "    annuity = np.sum(df_payments) * accrual\n",
    "    P_start = payoff_df_fn(expiry)\n",
    "    P_end = payoff_df_fn(expiry + tenor)\n",
    "    S0 = (P_start - P_end) / annuity if annuity > 0 else 0.0\n",
    "    price = hjm.price_swaption_mc(expiry=expiry, swap_tenor=tenor, fixed_rate=S0, payment_freq=payment_freq, payoff_df_fn=payoff_df_fn, n_paths=n_paths)\n",
    "    vol = implied_black_vol_from_price_swaption(S0=S0, K=S0, T=expiry, annuity=annuity, market_price=price)\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37c4c162-9466-4ae8-9c4b-49c3e9751fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Calibration: Stage A & Stage B\n",
    "# ---------------------------------\n",
    "def calibrate_stageA(hjm_template: HJMModel, atm_caplet: Dict[float,float], atm_swaption: Dict[Tuple[float,float],float],\n",
    "                     weights: Dict[str,float], bounds_phi: Dict[str,Tuple[float,float]] = None,\n",
    "                     fix_beta: Optional[float] = None, n_paths: int = 3): # 3 not 2000 n_paths to save speed on personal laptop\n",
    "    a0 = hjm_template.params.a\n",
    "    b0 = hjm_template.params.b\n",
    "    beta0 = hjm_template.params.beta if fix_beta is None else fix_beta\n",
    "    if bounds_phi is None:\n",
    "        bounds_phi = {\"a\": (1e-5, 0.5), \"b\": (0.0, 5.0), \"beta\": (-0.5, 1.5)}\n",
    "    def objective_x(x):\n",
    "        a, b, beta = x[0], x[1], (x[2] if fix_beta is None else fix_beta)\n",
    "        params = HJMParams(a=a, b=b, beta=beta, delta=hjm_template.params.delta,\n",
    "                           kappa=hjm_template.params.kappa, theta=hjm_template.params.theta,\n",
    "                           xi=hjm_template.params.xi, rho=hjm_template.params.rho, v0=hjm_template.params.v0)\n",
    "        hjm = HJMModel(times=hjm_template.Tgrid, f0=hjm_template.f0, params=params, n_steps_per_year=hjm_template.n_steps_per_year, \n",
    "                       seed=hjm_template.seed)\n",
    "        err_sq = 0.0\n",
    "        for Texp, mkt_vol in atm_caplet.items():\n",
    "            accrual = 0.25\n",
    "            try:\n",
    "                model_vol = model_caplet_implied_vol(hjm, expiry=Texp, accrual=accrual, strike=0.0, n_paths=n_paths)\n",
    "                if np.isnan(model_vol): continue\n",
    "                err_sq += weights.get(\"caplet\",1.0) * (model_vol - mkt_vol) ** 2\n",
    "            except Exception:\n",
    "                err_sq += 1e-4\n",
    "        for (Texp, Tten), mkt_vol in atm_swaption.items():\n",
    "            try:\n",
    "                model_vol = model_swaption_implied_vol(hjm, expiry=Texp, tenor=Tten, n_paths=n_paths)\n",
    "                if np.isnan(model_vol): continue\n",
    "                err_sq += weights.get(\"swaption\",1.0) * (model_vol - mkt_vol) ** 2\n",
    "            except Exception:\n",
    "                err_sq += 1e-4\n",
    "        return float(err_sq)\n",
    "    x0 = [a0, b0, beta0]\n",
    "    bnds = [bounds_phi[\"a\"], bounds_phi[\"b\"], bounds_phi[\"beta\"]]\n",
    "    res = optimize.minimize(objective_x, x0, method=\"L-BFGS-B\", bounds=bnds, options={\"maxiter\": 30})\n",
    "    a_fit, b_fit, beta_fit = float(res.x[0]), float(res.x[1]), float(res.x[2]) if fix_beta is None else fix_beta\n",
    "    result = {\"a\": a_fit, \"b\": b_fit, \"beta\": beta_fit, \"fun\": float(res.fun), \"success\": res.success}\n",
    "    print(\"Stage A finished:\", result)\n",
    "    return result\n",
    "\n",
    "def calibrate_stageB(hjm_template: HJMModel, caplet_df: pd.DataFrame, swaption_df: pd.DataFrame, weights: Dict[str,float],\n",
    "                     bounds_sv: Dict[str,Tuple[float,float]] = None, n_paths: int = 3): # 3 not 2000 n_paths to save speed on personal laptop\n",
    "    if bounds_sv is None:\n",
    "        bounds_sv = {\"kappa\": (1e-4, 10.0), \"theta\": (1e-6, 2.0), \"xi\": (1e-4, 3.0), \"rho\": (-0.99, 0.99), \"v0\": (1e-6, 2.0)}\n",
    "    cap_targets = []\n",
    "    for _, row in caplet_df.iterrows():\n",
    "        T = tenor_to_years(row[\"expiry\"])\n",
    "        cap_targets.append((\"caplet\", T, float(row[\"strike\"]), float(row[\"vol\"]), row[\"vol_type\"]))\n",
    "    swap_targets = []\n",
    "    for _, row in swaption_df.iterrows():\n",
    "        Texp = tenor_to_years(row[\"expiry\"]); Tten = tenor_to_years(row[\"tenor\"])\n",
    "        swap_targets.append((\"swaption\", Texp, Tten, row[\"moneyness\"], float(row[\"vol\"]), row[\"vol_type\"]))\n",
    "    def objective_y(y):\n",
    "        kappa, theta, xi, rho, v0 = y\n",
    "        params = HJMParams(a=hjm_template.params.a, b=hjm_template.params.b, beta=hjm_template.params.beta, delta=hjm_template.params.delta,\n",
    "                           kappa=kappa, theta=theta, xi=xi, rho=rho, v0=v0)\n",
    "        hjm = HJMModel(times=hjm_template.Tgrid, f0=hjm_template.f0, params=params, n_steps_per_year=hjm_template.n_steps_per_year, \n",
    "                       seed=hjm_template.seed)\n",
    "        err_sq = 0.0\n",
    "        for ttype, T, strike, mkt_vol, vtype in cap_targets:\n",
    "            try:\n",
    "                accrual = 0.25\n",
    "                price = hjm.price_caplet_mc(strike=strike, expiry=T, accrual=accrual, payoff_df_fn=payoff_df_fn, n_paths=n_paths)\n",
    "                idx = np.argmin(np.abs(hjm.Tgrid - (T + accrual)))\n",
    "                F0 = hjm.f0[idx]\n",
    "                DF = payoff_df_fn(T + accrual)\n",
    "                model_vol = implied_black_vol_from_price_caplet(price, F0, strike, accrual, DF)\n",
    "                if np.isnan(model_vol): continue\n",
    "                err_sq += weights.get(\"caplet\",1.0) * (model_vol - mkt_vol) ** 2\n",
    "            except Exception:\n",
    "                err_sq += 1.0\n",
    "        for ttype, Texp, Tten, mny, mkt_vol, vtype in swap_targets:\n",
    "            try:\n",
    "                model_vol = model_swaption_implied_vol(hjm, expiry=Texp, tenor=Tten, n_paths=n_paths)\n",
    "                if np.isnan(model_vol): continue\n",
    "                err_sq += weights.get(\"swaption\",1.0) * (model_vol - mkt_vol) ** 2\n",
    "            except Exception:\n",
    "                err_sq += 1.0\n",
    "        reg = 1e-6 * (kappa**2 + theta**2 + xi**2 + rho**2 + v0**2)\n",
    "        return float(err_sq + reg)\n",
    "    x0 = [hjm_template.params.kappa, hjm_template.params.theta, hjm_template.params.xi, hjm_template.params.rho, hjm_template.params.v0]\n",
    "    bnds = [bounds_sv[\"kappa\"], bounds_sv[\"theta\"], bounds_sv[\"xi\"], bounds_sv[\"rho\"], bounds_sv[\"v0\"]]\n",
    "    res = optimize.minimize(objective_y, x0, method=\"L-BFGS-B\", bounds=bnds, options={\"maxiter\": 30})\n",
    "    fitted = {\"kappa\": float(res.x[0]), \"theta\": float(res.x[1]), \"xi\": float(res.x[2]), \"rho\": float(res.x[3]), \"v0\": float(res.x[4]), \n",
    "              \"fun\": float(res.fun), \"success\": res.success}\n",
    "    print(\"Stage B finished:\", fitted)\n",
    "    return fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "591dbbf4-bd91-4299-b945-0ef89192177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Orchestration: main pipeline\n",
    "# ------------------------------\n",
    "def run_full_calibration(config: Dict):\n",
    "    \"\"\"\n",
    "    Orchestrate data ingestion, model initialisation, stage A and stage B calibration,\n",
    "    and produce outputs (plots, csvs, json).\n",
    "    \"\"\"\n",
    "    # 1. read data\n",
    "    curve_df_local = read_curve(curve_csv)\n",
    "    cap_df_local = pd.read_csv(caplet_csv)\n",
    "    swap_df_local = pd.read_csv(swaption_csv)\n",
    "\n",
    "    # 2. create HJM initial model template with default params\n",
    "    Tgrid = f0_times\n",
    "    f0 = f0_vals\n",
    "    params0 = HJMParams(a=config[\"phi_init\"][\"a\"], b=config[\"phi_init\"][\"b\"], beta=config[\"beta_init\"], delta=config[\"vol_shift\"],\n",
    "                        kappa=1.0, theta=0.04, xi=0.3, rho=-0.5, v0=0.04)\n",
    "    hjm_template = HJMModel(times=Tgrid, f0=f0, params=params0, n_steps_per_year=config[\"n_steps_per_year\"], seed=config[\"seed\"])\n",
    "\n",
    "    # 3. stage A: fit phi (a,b) & beta\n",
    "    weights_stageA = {\"caplet\": config[\"cap_weight\"], \"swaption\": config[\"swaption_weight\"]}\n",
    "    stageA_res = calibrate_stageA(hjm_template, atm_caplet, atm_swaption, weights={\"caplet\": weights_stageA[\"caplet\"], \"swaption\": \n",
    "                                                                                   weights_stageA[\"swaption\"]},\n",
    "                                  fix_beta=None if config[\"beta_init\"] is None else config[\"beta_init\"],\n",
    "                                  n_paths=config[\"n_paths_stageA\"])\n",
    "\n",
    "    # update template params\n",
    "    params_afterA = HJMParams(a=stageA_res[\"a\"], b=stageA_res[\"b\"], beta=stageA_res[\"beta\"], delta=params0.delta,\n",
    "                              kappa=params0.kappa, theta=params0.theta, xi=params0.xi, rho=params0.rho, v0=params0.v0)\n",
    "    hjm_afterA = HJMModel(times=Tgrid, f0=f0, params=params_afterA, n_steps_per_year=config[\"n_steps_per_year\"], seed=config[\"seed\"])\n",
    "\n",
    "    # 4. stage B: calibrate stochastic vol\n",
    "    weights_stageB = {\"caplet\": config[\"cap_weight\"], \"swaption\": config[\"swaption_weight\"]}\n",
    "    stageB_res = calibrate_stageB(hjm_afterA, cap_df_local, swap_df_local, weights=weights_stageB, n_paths=config[\"n_paths_stageB\"])\n",
    "\n",
    "    # 5. final model with fitted params\n",
    "    final_params = HJMParams(a=stageA_res[\"a\"], b=stageA_res[\"b\"], beta=stageA_res[\"beta\"], delta=params0.delta,\n",
    "                             kappa=stageB_res[\"kappa\"], theta=stageB_res[\"theta\"], xi=stageB_res[\"xi\"], rho=stageB_res[\"rho\"], v0=stageB_res[\"v0\"])\n",
    "    hjm_final = HJMModel(times=Tgrid, f0=f0, params=final_params, n_steps_per_year=config[\"n_steps_per_year\"], seed=config[\"seed\"])\n",
    "\n",
    "    # 6. diagnostics: compute model vs market ATM vols for both caplets and swaptions\n",
    "    # Caplets\n",
    "    model_cap_rows = []\n",
    "    for Texp, mkt_vol in atm_caplet.items():\n",
    "        accrual = 0.25\n",
    "        strike = 0.0\n",
    "        model_vol = model_caplet_implied_vol(hjm_final, expiry=Texp, accrual=accrual, strike=strike, n_paths=config[\"n_paths_stageA\"])\n",
    "        model_cap_rows.append({\"expiry\": Texp, \"market_vol\": mkt_vol, \"model_vol\": model_vol, \"error\": model_vol - mkt_vol})\n",
    "    df_caps = pd.DataFrame(model_cap_rows)\n",
    "    caps_out = os.path.join(config[\"output_dir\"], \"model_vs_market_caplets.csv\")\n",
    "    df_caps.to_csv(caps_out, index=False)\n",
    "\n",
    "    # Swaptions\n",
    "    model_swap_rows = []\n",
    "    for (Texp, Tten), mkt_vol in atm_swaption.items():\n",
    "        model_vol = model_swaption_implied_vol(hjm_final, expiry=Texp, tenor=Tten, n_paths=config[\"n_paths_stageA\"])\n",
    "        model_swap_rows.append({\"expiry\": Texp, \"tenor\": Tten, \"market_vol\": mkt_vol, \"model_vol\": model_vol, \"error\": model_vol - mkt_vol})\n",
    "    df_swaps = pd.DataFrame(model_swap_rows)\n",
    "    swaps_out = os.path.join(config[\"output_dir\"], \"model_vs_market_swaptions.csv\")\n",
    "    df_swaps.to_csv(swaps_out, index=False)\n",
    "\n",
    "    # 7. compute RMSE\n",
    "    cap_rmse = float(np.sqrt(np.nanmean(df_caps[\"error\"].dropna() ** 2)))\n",
    "    swap_rmse = float(np.sqrt(np.nanmean(df_swaps[\"error\"].dropna() ** 2)))\n",
    "    summary = {\"stageA\": stageA_res, \"stageB\": stageB_res, \"cap_rmse\": cap_rmse, \"swap_rmse\": swap_rmse}\n",
    "\n",
    "    # persist calibration_results.json\n",
    "    out_json = os.path.join(config[\"output_dir\"], \"calibration_results.json\")\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(\"Calibration summary saved:\", out_json)\n",
    "\n",
    "    # 8. plots\n",
    "    # ATM caplet vols\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_caps[\"expiry\"], df_caps[\"market_vol\"], marker='o', label=\"Market ATM Caplet\")\n",
    "    plt.plot(df_caps[\"expiry\"], df_caps[\"model_vol\"], marker='x', label=\"Model ATM Caplet\")\n",
    "    plt.xlabel(\"Expiry (years)\"); plt.ylabel(\"Vol\")\n",
    "    plt.title(\"ATM Caplet: Market vs Model\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(os.path.join(config[\"output_dir\"], \"plots\", \"atm_caplet_fit.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ATM swaption vols (pick by tenor)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    for tenor in sorted(set(df_swaps[\"tenor\"])):\n",
    "        sel = df_swaps[df_swaps[\"tenor\"]==tenor]\n",
    "        plt.plot(sel[\"expiry\"], sel[\"market_vol\"], marker='o', label=f\"Market tenor {tenor}y\")\n",
    "        plt.plot(sel[\"expiry\"], sel[\"model_vol\"], marker='x', linestyle='--', label=f\"Model tenor {tenor}y\")\n",
    "    plt.xlabel(\"Expiry (years)\"); plt.ylabel(\"Vol\"); plt.title(\"ATM Swaption Surface: Market vs Model\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(os.path.join(config[\"output_dir\"], \"plots\", \"atm_swaption_fit.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # 9. save parameters JSON\n",
    "    params_out = os.path.join(config[\"output_dir\"], \"calibrated_parameters.json\")\n",
    "    with open(params_out, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"final_params\": final_params.__dict__,\n",
    "            \"rmse\": {\"cap\": cap_rmse, \"swap\": swap_rmse}\n",
    "        }, f, indent=2)\n",
    "    print(\"Saved calibrated parameters:\", params_out)\n",
    "\n",
    "    # 10. print summary\n",
    "    print(\"\\n=== Calibration SUMMARY ===\")\n",
    "    print(f\"Caplet RMSE: {cap_rmse:.6f}\")\n",
    "    print(f\"Swaption RMSE: {swap_rmse:.6f}\")\n",
    "    print(\"Final parameters:\")\n",
    "    print(json.dumps(final_params.__dict__, indent=2))\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25317f5a-ef43-47e9-802a-f28d6596b0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HJM calibration demo (fast mode). This will create outputs in outputs\n",
      "Stage A finished: {'a': 0.02, 'b': 0.5, 'beta': 0.0, 'fun': 22.343583090210004, 'success': True}\n",
      "Stage B finished: {'kappa': 1.0007740027924705, 'theta': 0.006796422922430871, 'xi': 0.05104995710985319, 'rho': -0.6371888607385758, 'v0': 0.006796422922430871, 'fun': 15.237724876679492, 'success': False}\n",
      "Calibration summary saved: outputs\\calibration_results.json\n",
      "Saved calibrated parameters: outputs\\calibrated_parameters.json\n",
      "\n",
      "=== Calibration SUMMARY ===\n",
      "Caplet RMSE: 2.877161\n",
      "Swaption RMSE: 0.014803\n",
      "Final parameters:\n",
      "{\n",
      "  \"a\": 0.02,\n",
      "  \"b\": 0.5,\n",
      "  \"beta\": 0.0,\n",
      "  \"delta\": 0.0001,\n",
      "  \"kappa\": 1.0007740027924705,\n",
      "  \"theta\": 0.006796422922430871,\n",
      "  \"xi\": 0.05104995710985319,\n",
      "  \"rho\": -0.6371888607385758,\n",
      "  \"v0\": 0.006796422922430871\n",
      "}\n",
      "\n",
      "Done. Key outputs in outputs\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Run the pipeline (demo)\n",
    "# -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running HJM calibration demo (fast mode). This will create outputs in\", CONFIG[\"output_dir\"])\n",
    "    # remove old outputs for a fresh run (optional)\n",
    "    if os.path.exists(CONFIG[\"output_dir\"]):\n",
    "        try:\n",
    "            shutil.rmtree(CONFIG[\"output_dir\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "    ensure_dirs()\n",
    "    run_summary = run_full_calibration(CONFIG)\n",
    "    print(\"\\nDone. Key outputs in\", CONFIG[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b4502f-334e-4768-bc93-c12ca6877a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
